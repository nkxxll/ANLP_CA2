{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "from scripts.steam_review_dataset import SteamReviewDataset\n",
    "from scripts.annotations import update_df_review_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                                             review  voted_up  \\\n",
      "0          0  hogwarts legacy be a pretty decent open world ...      True   \n",
      "1          1  we demand an update to fix the crash issue mys...     False   \n",
      "2          2  overall i enjoy it but some downside choice do...      True   \n",
      "3          3  i enjoy the game but definitely would not say ...      True   \n",
      "4          4  b a beautiful yet shallow dive into the wizard...      True   \n",
      "\n",
      "   votes_up  weighted_vote_score  app_id  \n",
      "0       374             0.948440  990080  \n",
      "1       722             0.928115  990080  \n",
      "2       335             0.922237  990080  \n",
      "3       213             0.920985  990080  \n",
      "4       184             0.911110  990080  \n"
     ]
    }
   ],
   "source": [
    "# Lade die Daten\n",
    "df = pd.read_csv(\"../data/reviews_100k_cleaned_new.csv.bz2\")\n",
    "\n",
    "# Lade labels\n",
    "with open(\"./scripts/results/results-v2-2025-02-03T19_58_54.749839-nall-llama3.2.json\", \"r\") as fi:\n",
    "    labels = json.load(fi)\n",
    "\n",
    "labels = {int(k):v for k,v in labels.items()} # str keys to int\n",
    "\n",
    "print(df.head(n=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping 12 unique labels: gamemode, sound, gameplay, bugs, price, seasonal_content, hardware_requirements, story, updates, support, visuals, online_play\n",
      "       gamemode  sound  gameplay  bugs\n",
      "214         0.0    0.0       0.0   1.0\n",
      "719         0.0    0.0       0.0   0.0\n",
      "978         0.0    1.0       1.0   0.0\n",
      "2832        1.0    0.0       1.0   0.0\n",
      "3342        0.0    0.0       0.0   0.0\n",
      "...         ...    ...       ...   ...\n",
      "89571       0.0    0.0       0.0   0.0\n",
      "89576       0.0    1.0       1.0   0.0\n",
      "89638       1.0    0.0       0.0   0.0\n",
      "90213       0.0    0.0       0.0   0.0\n",
      "90231       0.0    0.0       0.0   0.0\n",
      "\n",
      "[218 rows x 4 columns]\n",
      "gamemode    10.0\n",
      "sound        9.0\n",
      "gameplay    66.0\n",
      "bugs        14.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "# see https://discuss.pytorch.org/t/multi-label-classification-in-pytorch/905/44\n",
    "\n",
    "\n",
    "df = update_df_review_labels(df, labels)\n",
    "df = df.dropna() # 94079 -> 218 rows\n",
    "\n",
    "print(df.loc[:, \"gamemode\":\"bugs\"])\n",
    "\n",
    "print(df.loc[:, \"gamemode\":\"bugs\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       review_id                                             review  voted_up  \\\n",
      "214          218  game be good but since the last patch a few da...     False   \n",
      "719          738  pro game be absolutely one of the prettiest ga...      True   \n",
      "978         1001  i would not recommend if you just want to play...     False   \n",
      "2832        2891  c go be an absolute classic that continue to s...      True   \n",
      "3342        3419  c remain an endure classic in the realm of com...      True   \n",
      "...          ...                                                ...       ...   \n",
      "89571      93817  brilliant fulfilling game you can do load with...      True   \n",
      "89576      93822  get it day ago and it be a very fun game it be...      True   \n",
      "89638      93887  a lot of basic feature break or do not wont th...     False   \n",
      "90213      94474  realy a monday morning game when change anythi...     False   \n",
      "90231      94493  the only question people ask me when i say i b...      True   \n",
      "\n",
      "       votes_up  weighted_vote_score   app_id  gamemode  sound  gameplay  \\\n",
      "214           3             0.545455   990080       0.0    0.0       0.0   \n",
      "719           1             0.523810   990080       0.0    0.0       0.0   \n",
      "978           3             0.511873   990080       0.0    1.0       1.0   \n",
      "2832          1             0.523810      730       1.0    0.0       1.0   \n",
      "3342          1             0.522472      730       0.0    0.0       0.0   \n",
      "...         ...                  ...      ...       ...    ...       ...   \n",
      "89571         0             0.000000  1248130       0.0    0.0       0.0   \n",
      "89576         0             0.000000  1248130       0.0    1.0       1.0   \n",
      "89638         1             0.480281  1248130       1.0    0.0       0.0   \n",
      "90213         2             0.478227  1248130       0.0    0.0       0.0   \n",
      "90231         1             0.517767  1248130       0.0    0.0       0.0   \n",
      "\n",
      "       bugs  price  seasonal_content  hardware_requirements  story  updates  \\\n",
      "214     1.0    0.0               0.0                    0.0    0.0      1.0   \n",
      "719     0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "978     0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "2832    0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "3342    0.0    0.0               0.0                    0.0    0.0      1.0   \n",
      "...     ...    ...               ...                    ...    ...      ...   \n",
      "89571   0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "89576   0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "89638   0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "90213   0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "90231   0.0    0.0               0.0                    0.0    0.0      0.0   \n",
      "\n",
      "       support  visuals  online_play  \n",
      "214        1.0      0.0          0.0  \n",
      "719        1.0      0.0          1.0  \n",
      "978        0.0      0.0          0.0  \n",
      "2832       0.0      0.0          0.0  \n",
      "3342       1.0      0.0          0.0  \n",
      "...        ...      ...          ...  \n",
      "89571      0.0      0.0          0.0  \n",
      "89576      0.0      1.0          0.0  \n",
      "89638      0.0      0.0          0.0  \n",
      "90213      1.0      0.0          1.0  \n",
      "90231      0.0      0.0          0.0  \n",
      "\n",
      "[218 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 218\n",
      "Train size: 130\n",
      "Validation size: 44\n",
      "Test size: 44\n"
     ]
    }
   ],
   "source": [
    "# Aufteilen in Train+Validation und Test (80/20 Split)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42 # TODO stratify causes issues with multilabel targets\n",
    ")\n",
    "\n",
    "# Aufteilen von Train+Validation in Training und Validation (75/25 von Train+Val)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Überprüfe die Größe der Splits\n",
    "print(f\"Original size: {len(df)}\")\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape: torch.Size([32, 200]), Labels shape: torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "# Erstelle Dataset-Objekte\n",
    "tokenizer = spm.SentencePieceProcessor(model_file=\"../data/reviews_unigram.model\")\n",
    "max_len = 200  # 91% der Reviews haben weniger als 200 Tokens\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = SteamReviewDataset(data=train_df, tokenizer=tokenizer, max_len=max_len, topic_mode=True)\n",
    "val_dataset = SteamReviewDataset(data=val_df, tokenizer=tokenizer, max_len=max_len, topic_mode=True)\n",
    "test_dataset = SteamReviewDataset(data=test_df, tokenizer=tokenizer, max_len=max_len, topic_mode=True)\n",
    "\n",
    "# Erstelle DataLoader für jeden Split\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Batch Shape\n",
    "for tokens, labels in train_loader:\n",
    "    print(f\"Tokens shape: {tokens.shape}, Labels shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 324,   40,    4,    8,   18,   98,    5,  191,  659,   22,   92,   21,\n",
      "          39,    4,  237,   16,  310,  454,  829,    6,   53,   31, 1004,   11,\n",
      "          87,  182,   17,    7,  890,  385,   48,    9,  668, 1640,  194,   76,\n",
      "           9,  215, 2078,   21,    4,  334,  228, 1450,   12,    4,    8,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]), tensor([0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        gru_layers: int,\n",
    "        hidden_dim: int,\n",
    "        dropout: float,\n",
    "        output_dim: int,\n",
    "        pad_idx: int,\n",
    "    ):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=pad_idx\n",
    "        )\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            num_layers=gru_layers,\n",
    "            hidden_size=hidden_dim,\n",
    "            dropout=dropout if gru_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "\n",
    "        gru_out, _ = self.gru(embedded)  # (batch_size, seq_length, hidden_dim)\n",
    "\n",
    "        last_hidden_state = gru_out[:, -1, :]  # (batch_size, hidden_dim)\n",
    "\n",
    "        output = self.fc(last_hidden_state)  # (batch_size, output_dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: GRUClassifier,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device=torch.device(\"cpu\"),\n",
    "):\n",
    "    # Loss und Optimizer definieren\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4, fused=False)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.1, patience=1\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Start training on device '{device}'\")\n",
    "\n",
    "    # Early Stopping Parameter\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    last_epoch = 0\n",
    "\n",
    "    # Listen für Visualisierung\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    # Training und Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_labels = []\n",
    "        train_preds = []\n",
    "\n",
    "        train_progress = tqdm(\n",
    "            train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", ncols=100\n",
    "        )\n",
    "\n",
    "        epoch_start_time = time.time()  # Startzeit für die Epoche\n",
    "\n",
    "        # Trainingsloop\n",
    "        for batch in train_progress:\n",
    "            tokens, labels = batch\n",
    "            print(f\"tokens = {tokens}, labels = {labels}\")\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            # Backward Pass und Optimierung\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Berechne Predictions und füge sie zur Liste hinzu\n",
    "            train_preds += (outputs.squeeze() > 0.5).cpu().numpy().tolist()\n",
    "            train_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "            # Update TQDM mit dem aktuellen Loss\n",
    "            train_progress.set_postfix(\n",
    "                loss=f\"{running_loss / (train_progress.n + 1):.3f}\"\n",
    "            )\n",
    "\n",
    "        # Berechne Trainings-Accuracy\n",
    "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validierung\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                tokens, labels = batch\n",
    "                tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(tokens)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds += (outputs.squeeze() > 0.5).cpu().numpy().tolist()\n",
    "                val_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "        scheduler.step(val_loss)  # Scheduler mit Validierungs-Loss aufrufen\n",
    "\n",
    "        # Berechne Validierungs-Accuracy\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        mins, secs = divmod(epoch_duration, 60)\n",
    "\n",
    "        print(\n",
    "            \"├ \"\n",
    "            f\"Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "            f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "            f\"Validation Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "            f\"Validation Accuracy: {val_accuracy:.4f}, \"\n",
    "            f\"Time: {int(mins):2}:{secs:.2f}m\"\n",
    "        )\n",
    "\n",
    "        # Early Stopping Überprüfung\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            print(\n",
    "                f\"└ Validation accuracy improved: {best_val_accuracy:.4f} → {val_accuracy:.4f}\"\n",
    "            )\n",
    "            best_val_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()  # Speichere das beste Modell\n",
    "            last_epoch = epoch\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(\n",
    "                f\"└ No improvement in validation accuracy. \"\n",
    "                f\"Patience counter: {patience_counter}/{patience}. Using LR: {scheduler.get_last_lr()[0]:.1e}\",\n",
    "            )\n",
    "            # Überprüfe, ob Early Stopping ausgelöst werden soll\n",
    "            if patience_counter >= patience:\n",
    "                print(\n",
    "                    \"Early stopping triggered! \"\n",
    "                    f\"Best Validation Accuracy: {best_val_accuracy:.2f}, on epoch {last_epoch+1}\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    # Lade das beste Modell zurück, falls Early Stopping ausgelöst wurde\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    print(\n",
    "        f\"Finished Training: Best Validation Accuracy: {best_val_accuracy:.2f}, on epoch {last_epoch+1}\"\n",
    "    )\n",
    "\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUClassifier(\n",
      "  (embedding): Embedding(4000, 128, padding_idx=0)\n",
      "  (gru): GRU(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Lade den Tokenizer, um `vocab_size` und `pad_id` zu erhalten\n",
    "tokenizer = spm.SentencePieceProcessor(model_file=\"../data/reviews_unigram.model\")\n",
    "vocab_size = tokenizer.get_piece_size()\n",
    "pad_idx = tokenizer.pad_id()\n",
    "\n",
    "# Modellparameter\n",
    "embedding_dim = 128\n",
    "gru_layers = 1\n",
    "hidden_dim = 256\n",
    "output_dim = 10\n",
    "dropout = 0.5\n",
    "\n",
    "# Initialisiere das GRU-Modell\n",
    "model = GRUClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    gru_layers=gru_layers,\n",
    "    hidden_dim=hidden_dim,\n",
    "    dropout=dropout,\n",
    "    output_dim=output_dim,\n",
    "    pad_idx=pad_idx,\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on device 'cuda'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]:   0%|                                                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens = tensor([[   8,    5,   37,  ...,    0,    0,    0],\n",
      "        [1802,  661, 1802,  ...,   22,   17,    9],\n",
      "        [ 249,  965,   54,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  10,   70,   14,  ...,    0,    0,    0],\n",
      "        [ 477,    7,  122,  ...,    0,    0,    0],\n",
      "        [ 957,  584, 1754,  ...,    0,    0,    0]]), labels = tensor([[0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]:   0%|                                                          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32, 4])) must be the same as input size (torch.Size([32, 10]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m----> 5\u001b[0m trained_model, train_losses, val_losses, train_accuracies, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 53\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, epochs, lr, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(tokens)\n\u001b[1;32m---> 53\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Backward Pass und Optimierung\u001b[39;00m\n\u001b[0;32m     56\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\cedri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cedri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cedri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:731\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cedri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3224\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3221\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 3224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([32, 4])) must be the same as input size (torch.Size([32, 10]))"
     ]
    }
   ],
   "source": [
    "# Trainiere das Modell\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Loss Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xticks(range(1, len(epochs) + 1))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\")\n",
    "    plt.xticks(range(1, len(epochs) + 1))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy Over Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Anzeigen\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_results(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Testen des Modells mit zusätzlichen Metriken\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Setze das Modell in den Eval-Modus\n",
    "    test_loss = 0.0\n",
    "    test_labels = []\n",
    "    test_preds = []\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung für Test\n",
    "        for batch in test_loader:\n",
    "            tokens, labels = batch\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(tokens)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Berechne Vorhersagen und füge sie zur Liste hinzu\n",
    "            test_preds += (outputs.squeeze() > 0.5).cpu().numpy().tolist()\n",
    "            test_labels += labels.cpu().numpy().tolist()\n",
    "\n",
    "    # Berechne Metriken\n",
    "    test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "    test_precision = precision_score(test_labels, test_preds)\n",
    "    test_recall = recall_score(test_labels, test_preds)\n",
    "    test_f1 = f1_score(test_labels, test_preds)\n",
    "\n",
    "    # Ausgabe der Metriken\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "    return test_labels, test_preds\n",
    "\n",
    "\n",
    "# Teste das Modell\n",
    "test_labels, test_preds = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        confusion_matrix(y_true, y_pred),\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        cbar=False,\n",
    "        xticklabels=[\"Negative\", \"Positive\"],\n",
    "        yticklabels=[\"Negative\", \"Positive\"],\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "**Hardware Specs:**\n",
    "- CPU: AMD Ryzen 7 3700X 8-Core\n",
    "- GPU: Nvidia GeForce RTX 3060 Ti\n",
    "- RAM: 48GB\n",
    "- OS: Linux Mint 22.1\n",
    "\n",
    "**Training Results**\n",
    "\n",
    "| Device | GRULayers | Dropout | EmbeddingDim | HiddenDim | VocabSize |     LR | Epoch | time/Epoch | TestAcc    | TestF1     |\n",
    "| ------ | --------: | ------: | -----------: | --------: | --------: | -----: | ----: | ---------- | ---------- | ---------- |\n",
    "| CPU    |         1 |       0 |          128 |       256 |     8.000 |  0.001 |     5 | 03:41      | ?          | ?          |\n",
    "| Cuda   |         1 |       0 |          128 |       128 |     4.000 |  0.001 |     5 | 00:20      | 0.9096     | 0.9337     |\n",
    "| Cuda   |         1 |       0 |          128 |       256 |     4.000 |  0.001 |     4 | 00:28      | **0.9110** | **0.9347** |\n",
    "| Cuda   |         1 |       0 |          128 |       256 |     8.000 |  0.001 |    13 | 00:28      | 0.9019     | 0.9273     |\n",
    "| Cuda   |         1 |       0 |          128 |       512 |     4.000 |  0.001 |    12 | 00:37      | 0.9013     | 0.9271     |\n",
    "| Cuda   |         1 |       0 |          256 |       256 |     8.000 |  0.001 |    10 | 00:28      | 0.9051     | 0.9296     |\n",
    "| Cuda   |         1 |       0 |          512 |       256 |     4.000 |  0.001 |    10 | 00:29      | 0.8897     | 0.9175     |\n",
    "| Cuda   |         1 |       0 |          512 |       256 |    17.000 |  0.001 |     5 | 00:29      | 0.8781     | 0.9063     |\n",
    "| Cuda   |         1 |       0 |          512 |       256 |    17.000 | 0.0001 |     5 | 00:29      | 0.8929     | 0.9190     |\n",
    "| Cuda   |         1 |       0 |          512 |      1024 |     4.000 |  0.001 |     8 | 01:17      | 0.9022     | 0.9275     |\n",
    "| Cuda   |         2 |     0.3 |          128 |       256 |     4.000 |  0.001 |     9 | 00:37      | 0.8875     | 0.9151     |\n",
    "| Cuda   |         2 |     0.3 |          128 |       512 |     4.000 |  0.001 |     9 | 00:55      | 0.8915     | 0.9210     |\n",
    "| Cuda   |         2 |     0.3 |          256 |       512 |     4.000 |  0.001 |    10 | 00:56      | 0.8992     | 0.9260     |\n",
    "| Cuda   |         2 |     0.5 |          256 |      1024 |     4.000 |  0.001 |     4 | 02:13      | 0.8542     | 0.8855     |\n",
    "| Cuda   |         2 |     0.5 |          512 |      1024 |     4.000 |  0.001 |     7 | 02:18      | 0.9103     | 0.9340     |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
