{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "from scripts.review_dataloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA version 12.1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"Using CUDA version {torch.version.cuda}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS backend\")\n",
    "else:\n",
    "    print(\"No backend detected, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 20000 reviews\n"
     ]
    }
   ],
   "source": [
    "# review_dl = SteamReviewDataset(\"../data/reviews_100k.csv.bz2\", shuffle=True)\n",
    "\n",
    "reviews_df = pd.read_csv(\"../data/reviews_100k.csv.bz2\", low_memory=False)\n",
    "reviews_df[\"review\"] = reviews_df[\"review\"].astype(str)\n",
    "reviews_df \n",
    "\n",
    "# optionally shuffle (games are in order!)\n",
    "reviews_df = reviews_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fewer data for testing\n",
    "# 100k full corpus takes 5h+\n",
    "# 10k takes 3 min\n",
    "# 1k takes 1s\n",
    "reviews_df = reviews_df[:20_000] \n",
    "\n",
    "print(f\"loaded {len(reviews_df):,} reviews\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train true/false ratio is 0.68\n",
      "y_test true/false ratio is 0.69\n"
     ]
    }
   ],
   "source": [
    "# Daten aufsplitten\n",
    "x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(reviews_df[\"review\"], reviews_df[\"voted_up\"], test_size=.33, random_state=42)   \n",
    "\n",
    "# Kontrolle\n",
    "print(f\"y_train true/false ratio is {len(y_train_raw[y_train_raw == True])/len(y_train_raw):.2f}\")\n",
    "print(f\"y_test true/false ratio is {len(y_test_raw[y_test_raw == True])/len(y_test_raw):.2f}\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build feature representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aah' 'aah man' 'aah man that' 'aah what' 'aah what lovely' 'ab' 'ab rb'\n",
      " 'ab rb or' 'ab system' 'ab system this']\n"
     ]
    }
   ],
   "source": [
    "tfid_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# ca. 45s\n",
    "x_train_tfidf = tfid_vectorizer.fit_transform(x_train_raw) # document term matrix\n",
    "x_test_tfidf = tfid_vectorizer.transform(x_test_raw)\n",
    "\n",
    "print(tfid_vectorizer.get_feature_names_out()[:10]) # Vorschau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "(1, 972118)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How the data looks\n",
    "# can't load whole dataset als dense matrix (1.5 TB!)\n",
    "test: np.matrix = scipy.sparse.csr_matrix.todense(x_train_tfidf[2]) # from scipy.sparse.csr_matrix.todense(x_train)\n",
    "print(type(test))\n",
    "print(test.shape) # (1, 3317704)\n",
    "np.count_nonzero(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure PyTorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalDataLoader(Dataset):\n",
    "    def __init__(self, reviews, labels):\n",
    "        self.reviews = reviews\n",
    "        self.labels = np.array(y_train_raw)\n",
    "        print(self.reviews.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.reviews.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = torch.tensor(scipy.sparse.csr_matrix.todense(self.reviews[idx]), dtype=torch.float32, device=torch.device('cuda:0')).squeeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32, device=torch.device('cuda:0'))\n",
    "        return review, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13400, 972118)\n",
      "13400\n"
     ]
    }
   ],
   "source": [
    "train_data_provider = MinimalDataLoader(x_train_tfidf, y_train_raw)\n",
    "print(len(train_data_provider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'),\n",
       " tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_provider.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module): # could also do this with nn.Sequential()\n",
    "    def __init__(self, input_dim): # input shape depends on tfidf matrix shape\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train_loader, input_dim, num_epochs=10, lr=0.001, device=\"cuda:0\"):\n",
    "    model = BinaryClassifier(input_dim=input_dim).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # iterating\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for batch_X, batch_y in progress_bar:\n",
    "            optimizer.zero_grad() # reset gradients\n",
    "            outputs = model(batch_X).squeeze() # fit weights\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed. Average Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 419/419 [01:27<00:00,  4.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 completed. Average Loss: 0.3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 419/419 [01:26<00:00,  4.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 completed. Average Loss: 0.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 419/419 [01:34<00:00,  4.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 completed. Average Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 419/419 [01:36<00:00,  4.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 completed. Average Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 419/419 [01:26<00:00,  4.87batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 completed. Average Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "input_dim = x_train_tfidf.shape[1]\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "train_loader = DataLoader(train_data_provider, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(train_loader, input_dim=input_dim, num_epochs=5, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated by gpt\n",
    "def evaluate_model(model, test_loader, device=\"cuda:0\"):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            # Move data to device (GPU or CPU)\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(batch_X).squeeze()\n",
    "            predictions = (outputs >= 0.5).float()  # Apply a threshold of 0.5\n",
    "            \n",
    "            all_preds.append(predictions.cpu().numpy())  # Collect predictions\n",
    "            all_targets.append(batch_y.cpu().numpy())   # Collect true labels\n",
    "\n",
    "    # Flatten the lists to evaluate metrics\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    precision = precision_score(all_targets, all_preds)\n",
    "    recall = recall_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6600, 972118)\n",
      "Accuracy: 0.5676\n",
      "Precision: 0.6948\n",
      "Recall: 0.6671\n",
      "F1 Score: 0.6807\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test dataset and DataLoader\n",
    "test_dataset = MinimalDataLoader(x_test_tfidf, y_test_raw)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(trained_model, test_loader)\n",
    "\n",
    "\n",
    "# Current Highscores\n",
    "\n",
    "# 10k samples batch 32\n",
    "# Accuracy: 0.5545\n",
    "# Precision: 0.6795\n",
    "# Recall: 0.6615\n",
    "# F1 Score: 0.6704\n",
    "\n",
    "# 20k samples batch 32\n",
    "# Accuracy: 0.5676\n",
    "# Precision: 0.6948\n",
    "# Recall: 0.6671\n",
    "# F1 Score: 0.6807"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
